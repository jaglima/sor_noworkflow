{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summer of Reproducibility - noWorkflow base experiment - Notebook 2\n",
    "\n",
    "This Jupyter Notebook dedicated to walk you through noWorkflow applications in Data Science and Machine Learning. It is result of our work in the Summer of Reproducibility from OSPO UCSC 2023 with [noWorkflow](https://github.com/gems-uff/noworkflow).\n",
    "\n",
    "This Notebook is an usecase based on the problem of Fraud Detection. We partially replicates the work \"The effect of feature extraction and data sampling on credit card fraud detection\". The interested reader is invited to consult the original work [here].(https://link.springer.com/article/10.1186/s40537-023-00684-w). \n",
    "\n",
    "For the sake of clarity, we splited this experiment in three steps into different Notebooks. \n",
    "1. Contemplates the steps from reading the dataset to Random Forest training, configuring one trial. \n",
    "2. Repeates all previous steps, but with changes in the experimental setup, like hyperparameters changed.\n",
    "3. Repeates all precisou steps, changing the order and the modeling choice of the initial trial.\n",
    "3. From previous results, noWorkflow is used to summarize and these trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "\n",
    "from noworkflow.now.tagging.var_tagging import backward_deps, \\\n",
    "    global_backward_deps, store_operations, resume_trials, trial_diff, \\\n",
    "    trial_intersection_diff, var_tag_plot, var_tag_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering stage\n",
    "\n",
    "Separate the features and target variable. First step in feature treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Apply PCA for feature extraction.\n",
    "\n",
    "Here we define *pca_components* tag to keep the n_components argument in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=33, checkpoint=29.209392186, code_component_id=870, activation_id=30, repr=5)\n"
     ]
    }
   ],
   "source": [
    "pca_components = now_variable('pca_components', 5)\n",
    "pca = PCA(n_components=pca_components)  # Adjust the number of components as needed\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Apply random undersampling over the extracted features\n",
    "\n",
    "Another case of feature engineering operation with hyperparameter definition. Here is *random_state* value for RandomUnderSampler function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=51, checkpoint=30.242671309, code_component_id=903, activation_id=48, repr=123456)\n"
     ]
    }
   ],
   "source": [
    "random_seed = now_variable('random_seed', 123456)\n",
    "rus = RandomUnderSampler(random_state=random_seed)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_pca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature engineering: Spliting dataset into train and test\n",
    "\n",
    "Here we have two hyperparameters assignments: the proportion of the test_size and the random_state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=70, checkpoint=30.413706623, code_component_id=939, activation_id=67, repr=0.3)\n"
     ]
    }
   ],
   "source": [
    "test_dim = now_variable('test_dim', 0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_dim, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring: model training and transforming features into predictions\n",
    "##### RandomForest\n",
    "\n",
    "Instantiate and evaluate a Random Forest Classifier. Here we are tagging the model name in a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=89, checkpoint=30.522698816, code_component_id=973, activation_id=85, repr=RandomForestClassifier())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = now_variable('model', RandomForestClassifier())\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluating: evaluating the performance of models\n",
    "##### RandomForest\n",
    "\n",
    "Computing performance metrics. Two control variables are tagged here. *roc_rf* stores the ROC score classical metric in classification. On the other hand, *f1_rf* is the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=111, checkpoint=30.785813846, code_component_id=1010, activation_id=100, repr=0.9288127853881278)\n",
      "Evaluation(id=120, checkpoint=30.788498385999997, code_component_id=1026, activation_id=100, repr=0.926829268292683)\n",
      "Random Forest - ROC = 0.928813, F1 = 0.926829\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "roc_rf = now_variable('roc_rf', roc_auc_score(y_test, y_pred_rf))\n",
    "f1_rf = now_variable('f1_rf', f1_score(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Random Forest - ROC = %f, F1 = %f\" % (roc_rf, f1_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_rf variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{26: ('y_test', 'complex data type'),\n",
       " 25: ('RandomForestClassifier()', 'complex data type'),\n",
       " 24: (\"now_variable('model', RandomForestClassifier())\", 'complex data type'),\n",
       " 23: ('rf', 'complex data type'),\n",
       " 22: ('X_resampled', 'complex data type'),\n",
       " 21: ('RandomUnderSampler(random_state=random_seed)', 'complex data type'),\n",
       " 20: ('rus', 'complex data type'),\n",
       " 19: (\"now_variable('pca_components', 5)\", '5'),\n",
       " 18: ('pca_components', '5'),\n",
       " 17: ('PCA(n_components=pca_components)', 'PCA(n_components=5)'),\n",
       " 16: ('pca', 'PCA(n_components=5)'),\n",
       " 15: ('X', 'complex data type'),\n",
       " 14: ('X_pca', 'complex data type'),\n",
       " 13: ('df', 'complex data type'),\n",
       " 12: (\"df['Class']\", 'complex data type'),\n",
       " 11: ('y', 'complex data type'),\n",
       " 10: ('y_resampled', 'complex data type'),\n",
       " 9: (\"now_variable('test_dim', 0.3)\", '0.3'),\n",
       " 8: ('test_dim', '0.3'),\n",
       " 7: (\"now_variable('random_seed', 123456)\", '123456'),\n",
       " 6: ('random_seed', '123456'),\n",
       " 5: ('train_test_split(X_resampled, y_resampled, test_size=test_dim, random_state=random_seed)',\n",
       "  'complex data type'),\n",
       " 4: ('X_test', 'complex data type'),\n",
       " 3: ('y_pred_rf', 'complex data type'),\n",
       " 2: ('roc_auc_score(y_test, y_pred_rf)', '0.9288127853881278'),\n",
       " 1: (\"now_variable('roc_rf', roc_auc_score(y_test, y_pred_rf))\",\n",
       "  '0.9288127853881278'),\n",
       " 0: ('roc_rf', '0.9288127853881278')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ops = backward_deps('roc_rf', False)\n",
    "dict_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_rf variable\n",
    "\n",
    "Save the operations dictionary in a shelve object with this trial_id as a key.\n",
    "\n",
    "Steps are:\n",
    "1. calls store operations() to store the dict into a shelve object with this trial_id key\n",
    "2. verify the list of stored trials available to comparision with resume_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary stored in shelve.\n"
     ]
    }
   ],
   "source": [
    "trial_id = __noworkflow__.trial_id\n",
    "store_operations(trial_id, dict_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d17fbfb6-428c-466f-8734-44c3c399984d',\n",
       " 'ad1f4984-7470-476f-aa31-6cb6ca348ea0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next steps\n",
    "\n",
    "In the next Notebook in this series, we will focus on comparing these two experiments with the noWorkflow "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noWorkflow 3",
   "language": "python",
   "name": "noworkflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd46906d0be51105938edee03e9704979453c4958d5b4d09c310e6ecda521c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
