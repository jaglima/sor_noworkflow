{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summer of Reproducibility - noWorkflow base experiment - Notebook 4\n",
    "\n",
    "This Jupyter Notebook is dedicated to guiding you through the applications of noWorkflow in Data Science and Machine Learning. It is the result of our work during the Summer of Reproducibility at OSPO UCSC 2023, utilizing [noWorkflow](https://github.com/gems-uff/noworkflow).\n",
    "\n",
    "This Notebook serves as a use case based on the problem of Fraud Detection. We have partially replicated the work titled \"The Effect of Feature Extraction and Data Sampling on Credit Card Fraud Detection.\" Interested readers are encouraged to refer to the original work [here].(https://link.springer.com/article/10.1186/s40537-023-00684-w).\n",
    "\n",
    "For the sake of clarity, we have divided this experiment into different notebooks:\n",
    "\n",
    "1. Covers the steps from reading the dataset to Random Forest training, configuring a single trial.\n",
    "2. Repeats all previous steps but with changes in the experimental setup, such as modified hyperparameters.\n",
    "3. Utilizes noWorkflow to summarize the results from previous trials.\n",
    "4. Repeats the experiment, changing the model and the order of operations.\n",
    "5. Compares the modifications and differences between the last and first experiments.\n",
    "\n",
    "**Please, remember to select the noWorkflow kernel before running these Notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from noworkflow.now.tagging.var_tagging import backward_deps, \\\n",
    "    global_backward_deps, store_operations, resume_trials, trial_diff, \\\n",
    "    trial_intersection_diff, var_tag_plot, var_tag_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering stage\n",
    "\n",
    "Separate the features and target variable. First step in feature treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Apply random undersampling over the extracted features\n",
    "\n",
    "In this experiment, we are inverting the sequence between RandomUnderSampler and PCA calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=33, checkpoint=23.406392426, code_component_id=710, activation_id=30, repr=42)\n"
     ]
    }
   ],
   "source": [
    "random_seed = now_variable('random_seed', 42)\n",
    "rus = RandomUnderSampler(random_state=random_seed)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Apply PCA for feature extraction.\n",
    "\n",
    "Here we define *pca_components* tag to keep the n_components argument in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=53, checkpoint=23.658996901, code_component_id=748, activation_id=50, repr=3)\n"
     ]
    }
   ],
   "source": [
    "pca_components = now_variable('pca_components', 3)\n",
    "pca = PCA(n_components=pca_components)  # Adjust the number of components as needed\n",
    "X_pca = pca.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature engineering: Spliting dataset into train and test\n",
    "\n",
    "Here we have two hyperparameters assignments: the proportion of the test_size and the random_state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=70, checkpoint=23.799512257, code_component_id=779, activation_id=67, repr=0.2)\n"
     ]
    }
   ],
   "source": [
    "test_dim = now_variable('test_dim', 0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_resampled, test_size=test_dim, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring: model training and transforming features into predictions\n",
    "##### XGBoost\n",
    "\n",
    "Instantiate and evaluate a XGBoost classifier. Here we are tagging the model name in a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=90, checkpoint=23.897578456999998, code_component_id=813, activation_id=85, repr=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, gamma=None,\n",
      "              gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, predictor=None, random_state=None,\n",
      "              reg_alpha=None, reg_lambda=None, ...))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = now_variable('model', xgb.XGBClassifier())\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluating: evaluating the performance of models\n",
    "##### RandomForest\n",
    "\n",
    "Computing performance metrics. Two control variables are tagged here. *roc_rf* stores the ROC score classical metric in classification. On the other hand, *f1_rf* is the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=111, checkpoint=24.08765099, code_component_id=851, activation_id=100, repr=0.8780663780663781)\n",
      "Evaluation(id=120, checkpoint=24.090723284, code_component_id=867, activation_id=100, repr=0.875)\n",
      "XGBoost - ROC = 0.878066, F1 = 0.875000\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "roc_metric = now_variable('roc_metric', roc_auc_score(y_test, y_pred))\n",
    "f1_metric = now_variable('f1_metric', f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"XGBoost - ROC = %f, F1 = %f\" % (roc_metric, f1_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_metric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: ('y_test', 'complex data type'),\n",
       " 24: (\"now_variable('model', xgb.XGBClassifier())\", 'complex data type'),\n",
       " 23: ('xgb_model', 'complex data type'),\n",
       " 22: (\"now_variable('pca_components', 3)\", '3'),\n",
       " 21: ('pca_components', '3'),\n",
       " 20: ('PCA(n_components=pca_components)', 'PCA(n_components=3)'),\n",
       " 19: ('pca', 'PCA(n_components=3)'),\n",
       " 18: ('X_resampled', 'complex data type'),\n",
       " 17: ('X_pca', 'complex data type'),\n",
       " 16: ('RandomUnderSampler(random_state=random_seed)', 'complex data type'),\n",
       " 15: ('rus', 'complex data type'),\n",
       " 14: ('X', 'complex data type'),\n",
       " 13: ('df', 'complex data type'),\n",
       " 12: (\"df['Class']\", 'complex data type'),\n",
       " 11: ('y', 'complex data type'),\n",
       " 10: ('y_resampled', 'complex data type'),\n",
       " 9: (\"now_variable('test_dim', 0.2)\", '0.2'),\n",
       " 8: ('test_dim', '0.2'),\n",
       " 7: (\"now_variable('random_seed', 42)\", '42'),\n",
       " 6: ('random_seed', '42'),\n",
       " 5: ('train_test_split(X_pca, y_resampled, test_size=test_dim, random_state=random_seed)',\n",
       "  'complex data type'),\n",
       " 4: ('X_test', 'complex data type'),\n",
       " 3: ('y_pred', 'complex data type'),\n",
       " 2: ('roc_auc_score(y_test, y_pred)', '0.8780663780663781'),\n",
       " 1: (\"now_variable('roc_metric', roc_auc_score(y_test, y_pred))\",\n",
       "  '0.8780663780663781'),\n",
       " 0: ('roc_metric', '0.8780663780663781')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ops = backward_deps('roc_metric', False)\n",
    "dict_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_metric\n",
    "Save the operations dictionary in a shelve object with this trial_id as a key.\n",
    "\n",
    "Steps are:\n",
    "1. calls store operations() to store the dict into a shelve object with this trial_id key\n",
    "2. verify the list of stored trials available to comparision with resume_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary stored in shelve.\n"
     ]
    }
   ],
   "source": [
    "trial_id = __noworkflow__.trial_id\n",
    "store_operations(trial_id, dict_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edb94455-f97b-46f0-b30e-ed01eaf81081',\n",
       " 'b86773c3-a3b7-40d0-a3ac-5ab4278826c2',\n",
       " 'c33177a6-88be-4f78-ae96-ede68a5ab142']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next steps\n",
    "The final [Notebook](./now_usecase_part_5.ipynb) will use the noWorkflow features to compare this experiment and the first one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noWorkflow 3",
   "language": "python",
   "name": "noworkflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd46906d0be51105938edee03e9704979453c4958d5b4d09c310e6ecda521c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
